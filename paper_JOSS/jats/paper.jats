<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.2 20190208//EN"
                  "JATS-publishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
<journal-title>Journal of Open Source Software</journal-title>
<abbrev-journal-title>JOSS</abbrev-journal-title>
</journal-title-group>
<issn publication-format="electronic">2475-9066</issn>
<publisher>
<publisher-name>Open Journals</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">0</article-id>
<article-id pub-id-type="doi">N/A</article-id>
<title-group>
<article-title>GAMMA_FLOW: <bold>G</bold>uided <bold>A</bold>nalysis of
<bold>M</bold>ulti-label spectra by <bold>Ma</bold>trix
<bold>f</bold>actorization for <bold>L</bold>ightweight
<bold>O</bold>perational <bold>W</bold>orkflows</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5852-0266</contrib-id>
<name>
<surname>Rädle</surname>
<given-names>Viola</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
<xref ref-type="corresp" rid="cor-1"><sup>*</sup></xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-6742-8843</contrib-id>
<name>
<surname>Hartwig</surname>
<given-names>Tilman</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Oesen</surname>
<given-names>Benjamin</given-names>
</name>
<xref ref-type="aff" rid="aff-1"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0005-8667-080X</contrib-id>
<name>
<surname>Vogt</surname>
<given-names>Julius</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5567-1010</contrib-id>
<name>
<surname>Gericke</surname>
<given-names>Eike</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-0249-7770</contrib-id>
<name>
<surname>Kröger</surname>
<given-names>Emily Alice</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3939-2104</contrib-id>
<name>
<surname>Baron</surname>
<given-names>Martin</given-names>
</name>
<xref ref-type="aff" rid="aff-2"/>
</contrib>
<aff id="aff-1">
<institution-wrap>
<institution>Application Lab for AI and Big Data, German Environmental
Agency, Leipzig, Germany</institution>
<institution-id institution-id-type="ROR">0329ynx05</institution-id>
</institution-wrap>
</aff>
<aff id="aff-2">
<institution-wrap>
<institution>Federal Office for Radiation Protection, Berlin,
Germany</institution>
<institution-id institution-id-type="ROR">02yvd4j36</institution-id>
</institution-wrap>
</aff>
</contrib-group>
<author-notes>
<corresp id="cor-1">* E-mail: <email></email></corresp>
</author-notes>
<pub-date date-type="pub" publication-format="electronic" iso-8601-date="2024-12-20">
<day>20</day>
<month>12</month>
<year>2024</year>
</pub-date>
<volume>¿VOL?</volume>
<issue>¿ISSUE?</issue>
<fpage>¿PAGE?</fpage>
<permissions>
<copyright-statement>Authors of papers retain copyright and release the
work under a Creative Commons Attribution 4.0 International License (CC
BY 4.0)</copyright-statement>
<copyright-year>1970</copyright-year>
<copyright-holder>The article authors</copyright-holder>
<license license-type="open-access" xlink:href="https://creativecommons.org/licenses/by/4.0/">
<license-p>Authors of papers retain copyright and release the work under
a Creative Commons Attribution 4.0 International License (CC BY
4.0)</license-p>
</license>
</permissions>
<kwd-group kwd-group-type="author">
<kwd>Python</kwd>
<kwd>Gamma spectroscopy</kwd>
<kwd>Non-negative matrix factorization</kwd>
<kwd>Classification</kwd>
<kwd>Multi-label spectra</kwd>
</kwd-group>
</article-meta>
</front>
<body>
<sec id="summary">
  <title>Summary</title>
  <p>Radioactive sources can be identified by measuring their emitted
  radiation (X-rays and gamma rays), and visualizing them as a spectrum.
  In nuclear security applications, the resulting gamma spectra have to
  be analyzed in real-time as immediate reaction and decision making may
  be required. However, the manual recognition of isotopes present in a
  spectrum constitutes a strenous, error-prone task that depends upon
  expert knowledge. Hence, this raises the need for algorithms assisting
  in the initial categorization and recognizability of measured gamma
  spectra.</p>
  <p>The delineated use case brings along several requirements:
  - As mobile, room temperature detectors are often deployed in nuclear
  security applications, the produced spectra typically exhibit a rather
  low energy resolution. In addition, a high temporal resolution is
  required (usually around one spectrum per second), leading to a low
  acquisition time and a low signal-to-noise ratio. Hence, the model
  must be robust and be able to handle noisy data.
  - For some radioactive sources, acquisition of training spectra may be
  challenging. Instead, spectra of those isotopes are simulated using
  Monte Carlo N-Particle (MCNP) code
  (<xref alt="Kulesza2022?" rid="ref-Kulesza2022" ref-type="bibr"><bold>Kulesza2022?</bold></xref>).
  In this process, energy deposition in a detector material is
  simulated, yielding spectra that can be used for model training.
  However, simulated spectra and measured spectra from real-world
  sources may differ, which may be a constraint for model performance.
  On this account, preliminary data exploration is crucial to assess the
  similarity of spectral data from different detectors and to evaluate
  potential data limitations.
  - At last, not only the correct classification of single-label test
  spectra (stemming from one isotope) is necessary, but also the
  decomposition of linear combinations of various isotopes (multi-label
  spectra). Hence, classification approaches like k-nearest-neighbours
  that solely depend on the similarity between training and test spectra
  are not applicable.</p>
  <p>This paper presents <monospace>gamma_flow</monospace>, a python
  package that includes the
  - classification of test spectra to predict their constituents
  - denoising of test spectra for better recognizability
  - outlier detection to evaluate the model’s applicability to test
  spectra</p>
  <p>It is based on a dimensionality reduction model that constitutes a
  novel, supervised approach to non-negative matrix factorization (NMF).
  More explicitly, the spectral data matrix is decomposed into the
  product of two low-rank matrices denoted as the scores (spectral data
  in latent space) and the loadings (transformation matrix or latent
  components). The loadings matrix is predefined and consists of the
  mean spectra of the training isotopes. Hence, by design, the scores
  axes correspond to the share of an isotope in a spectrum, resulting in
  an interpretable latent space.</p>
  <p>As a result, the classification of a test spectrum can be read
  directly from its (normalized) scores. In particular, shares of
  individual isotopes in a multi-label spectrum can be identified. This
  leads to an explainable quantitative prediction of the spectral
  constituents.</p>
  <p>The scores can be transformed back into spectral space by applying
  the inverse model. This inverse transformation rids the test spectrum
  of noise and results in a smooth, easily recognizable denoised
  spectrum.</p>
  <p>If a test spectrum of an isotope is unknown to the model (i.e. this
  isotope was not included in model training), it can still be projected
  into latent space. However, when the latent space information (scores)
  are decompressed, the resulting denoised spectrum does not resemble
  the original spectrum any more. Some original features may not be
  captured while new peaks may have been fabricated. This can be
  quantified by calculating the cosine similarity between the original
  and the denoised spectrum, which can serve as an indicator of a test
  spectrum to be an outlier.</p>
</sec>
<sec id="statement-of-need">
  <title>Statement of need</title>
  <p>In many research fields, spectral measurements help to assess
  material properties. In this context, an area of interest for many
  researchers is the classification (automated labelling) of the
  measured spectra. Proprietary spectral analysis software, however, are
  often limited in their functionality and adaptability
  <monospace>[@Lam2011; @Naseredding2023]</monospace>. In addition, the
  underlying mechanisms are usually not revealed and may act as a
  black-box system to the user <monospace>[@El Amri2022]</monospace>. On
  top of that, a spectral comparison is typically only possible for
  spectra of pure substances <monospace>[@Cowger:2021]</monospace>.
  However, there may be a need to decompound multi-label spectra (linear
  combinations of different substances) and identify their
  constituents.</p>
  <p><monospace>gamma_flow</monospace> is a Python package that can
  assist researchers in the classification, denoising and outlier
  detection of spectra. It includes data preprocessing, data
  exploration, model training and testing as well as an exploratory
  section on outlier detection. Making use of matrix decomposition
  methods, the designed model is lean and performant. Training and
  inference do not require special hardware or extensive computational
  power. This allows real-time application on ordinary laboratory
  computers and easy implementation into the measurement routine.</p>
  <p>The provided example dataset contains gamma spectra of several
  measured and simulated isotopes as well as pure background spectra.
  While this package was developed in need of an analysis tool for gamma
  spectra, it is suitable for any one-dimensional spectra. Examplary
  applications encompass - infrared spectroscopy for the assessment of
  the polymer composition of microplastics in water
  <monospace>[@Ferreiro:2023; @Whiting:2022]</monospace> - mass
  spectrometry for protein identification in snake venom
  <monospace>[@Zelanis:2019; @Yasemin:2021]</monospace> - raman
  spectroscopy for analysis of complex pharmaceutical mixtures and
  detection of dilution products like lactose
  <monospace>[@Fu:2021]</monospace> - UV-Vis spectroscopy for detection
  of pesticides in surface waters
  <monospace>[@Guo:2020; @Qi:2024]</monospace> - stellar spectroscopy to
  infer the chemical composition of stars
  <monospace>[@Gray:2021]</monospace></p>
</sec>
<sec id="methodology-and-structure">
  <title>Methodology and structure</title>
  <p>This python package consists of three jupyter notebooks that are
  executed consecutively. In this section, their functionality and is
  outlined, with an emphasis on the mathematical struction of the
  model.</p>
  <sec id="preprocessing-and-data-exploration">
    <title>Preprocessing and data exploration</title>
    <p>The notebook <monospace>01_preprocessing.ipynb</monospace>
    synchronizes spectral data and provides a framework of
    visualizations for data exploration. All functions called in this
    notebook are found in
    <monospace>tools_preprocessing.py</monospace>.</p>
    <p>During preprocessing, the following steps are performed:
    - Spectral data files are converted from .xlsm/.spe data to .npy
    format and saved.
    - Spectra of different energy calibrations are rebinned to a
    standard energy calibration.
    - Spectral data are aggregated by label classes and detectors. Thus,
    it is possible to collect data from different files and formats.
    - Optional: The spectra per isotope are limited to a maximum number.
    - The preprocessed spectra are saved as .npy files.</p>
    <p>Data exploration involves the following visualizations:
    - For each label class (e.g. for each isotope), the mean spectra are
    calculated detector-wise and compared quantitatively by the cosine
    similarity.
    - For each label class, example spectra are chosen randomly and
    plotted to provide an overview over the data.
    - The cosine similarity is calculated and visualized as a matrix for
    all label classes and detectors. This helps to assess whether the
    model can handle spectra from different detectors.</p>
  </sec>
  <sec id="model-training-and-testing">
    <title>Model training and testing</title>
    <p>The notebook <monospace>02_model.ipynb</monospace> trains and
    tests a dimensionality reduction model that allows for denoising,
    classification and outlier detection of test spectra. All functions
    called in this notebook are found in
    <monospace>tools_model.py</monospace>.</p>
    <p>The dimensionality reduction model presented in this paper
    comprises a matrix decomposition of spectral data. More precisely,
    the original spectra matrix <inline-formula><alternatives>
    <tex-math><![CDATA[X]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>X</mml:mi></mml:math></alternatives></inline-formula>
    is reconstructed by two low-rank matrices
    <inline-formula><alternatives>
    <tex-math><![CDATA[S]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>S</mml:mi></mml:math></alternatives></inline-formula>
    and <inline-formula><alternatives>
    <tex-math><![CDATA[L]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mi>L</mml:mi></mml:math></alternatives></inline-formula>:
    <disp-formula><alternatives>
    <tex-math><![CDATA[ X \approx S  L^{T} ]]></tex-math>
    <mml:math display="block" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:mrow><mml:mi>X</mml:mi><mml:mo>≈</mml:mo><mml:mi>S</mml:mi><mml:msup><mml:mi>L</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></disp-formula>
    with S: scores matrix (spectra in latent space)
    L: loadings matrix (transformation matrix or latent components)</p>
    <fig>
      <caption><p>Matrix decomposition of spectral data.
      <styled-content id="figU003Amatrix_decomposition"></styled-content></p></caption>
      <graphic mimetype="image" mime-subtype="png" xlink:href="figure_1.png" />
    </fig>
    <p>As illustrated in Figure
    <xref alt="[fig:matrix_decomposition]" rid="figU003Amatrix_decomposition">[fig:matrix_decomposition]</xref>,
    original spectral data can be compressed into
    <inline-formula><alternatives>
    <tex-math><![CDATA[k_\mathrm{isotopes}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>
    dimensions. To ensure a conclusive assignment of the latent space
    axes to the isotopes (i.e. one axis stands for of one isotope), the
    loadings matrix is predefined as the mean spectra of the
    <inline-formula><alternatives>
    <tex-math><![CDATA[k_\mathrm{isotopes}]]></tex-math>
    <mml:math display="inline" xmlns:mml="http://www.w3.org/1998/Math/MathML"><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>
    isotopes.</p>
    <p>During model training, mean spectra for all isotopes are
    calculated. The scores are then derived by non-negative least
    squares fit of the original spectra to the loadings matrix. Thus,
    the components of the normalized scores vectors directly reveal the
    contributions of the individual isotopes. Denoised spectra, on the
    other hand, are computed by transforming the non-normalized scores
    back into spectral space (i.e. by multiplication of with the
    loadings matrix).</p>
    <p>In mathematical terms, this model represents a ‘supervised’
    approach to Non-negative Matrix Factorization (NMF)
    <monospace>[@Shreeves:2020; @Bilton:2019]</monospace>. While
    dimensionality reduction is conventionally an unsupervised task as
    it only considers data structure
    <monospace>[@Olaya:2022]</monospace>, our approach integrates labels
    in model training. This leads to an interpretable latent space and
    obviates the need for an additional classification step. While other
    supervised NMF approaches incorporate classification loss in model
    training
    <monospace>[@Leuschner:2019; @Lee:2010; @Bisot:2016]</monospace>,
    our model focuses on a comprehensible construction of the latent
    space.</p>
    <p>The model is trained using spectral data from the specified
    detectors <monospace>dets_tr</monospace> and isotopes
    <monospace>isotopes_tr</monospace>. Subsequently, it is inferenced
    (i.e. scores are calculated) on three different test datasets: 1.
    validation data/holdout data from same detector as used in training
    (each spectrum including only one isotope or pure background) 2.
    test data from different detector (each spectrum including one
    isotope and background) 3. multi-label test data from different
    detector (each spectrum including multiple isotopes and
    background)</p>
    <p>For all test datasets, spectra are classified and denoised. The
    results are visualized as
    - confusion matrix
    - misclassified spectra
    - denoised example spectrum
    - misclassification statistics
    - scores as scatter matrix
    - mean scores as bar plot
    This helps to assess model performance with respect to
    classification and denoising.</p>
  </sec>
  <sec id="outlier-analysis">
    <title>Outlier analysis</title>
    <p>The notebook <monospace>03_outlier.ipynb</monospace> provides an
    exploratory approach to outliers detection, i.e. to identify spectra
    from isotopes that were not used in model training. All functions
    called in this notebook are found in
    <monospace>tools_outlier.py</monospace>.</p>
    <p>To simulate outlier spectra, a mock dataset is generated by
    training a model after removing one specific isotope. The trained
    model is then inferenced on spectra of this unknown isotope to
    investigate its behaviour with outliers. First, the resulting latent
    space distribution and further meta data are analyzed to distinguish
    known from unknown spectra. Using a decision tree, the most
    informative feature is identified. Next, a decision boundary is
    derived for this feature, by
    a) using the condition of the first split in the decision tree
    b) fitting a logistic regression (sigmoid function) to the data
    c) setting a manual threshold by considering accuracy, precision and
    recall of outlier identification.
    The derived decision boundary can then be implemented in the
    measurement pipeline by the user.</p>
  </sec>
</sec>
<sec id="acknowledgements">
  <title>Acknowledgements</title>
  <p>We gratefully acknowledge the support provided by the Federal
  Ministry for the Environment, Nature Conservation and Nuclear Safety
  (BMUV), whose funding has been instrumental in enabling us to achieve
  our research objectives and explore new directions. We also extend our
  appreciation to Martin Bussick in his function as the AI coordinator.
  Additionally, we thank the entire AI-Lab team for their support and
  inspiration, with special recognition to Ruth Brodte for guidance on
  legal and licensing matters.</p>
</sec>
</body>
<back>
</back>
</article>
