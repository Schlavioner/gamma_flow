%% 
%% Copyright 2007, 2008, 2009 Elsevier Ltd


\documentclass[preprint, 12pt, a4paper]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

\usepackage{amssymb} % math symbols
\usepackage{hyperref}
\setlength{\parindent}{0pt}
\tolerance=2000  % for better line breaks
\emergencystretch=10pt  % for better line breaks
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%\usepackage{lineno}

\journal{SoftwareX}

\begin{document}
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}}

\begin{frontmatter}

\title{\textbf{\textsc{gamma\_flow}}: \textbf{G}uided \textbf{A}nalysis of \textbf{M}ulti-label spectra by \textbf{Ma}trix \textbf{F}actorization for \textbf{L}ightweight \textbf{O}perational \textbf{W}orkflows}

\author[ki-lab]{Viola Rädle \corref{cor1}}
\author[ki-lab]{Tilman Hartwig}
\author[ki-lab]{Benjamin Oesen}
\author[bfs]{Emily Alice Kröger}
\author[bfs]{Julius Vogt}
\author[bfs]{Eike Gericke}
\author[bfs]{Martin Baron}

\address[ki-lab]{Application Lab for AI and Big Data, German Environmental Agency, Leipzig, Germany}
\address[bfs]{Federal Office for Radiation Protection, Berlin, Germany}

\cortext[cor1]{Corresponding author: raedle.htwk - AT - web.de}


\begin{abstract}
\textsc{gamma\_flow} is an open-source Python package for real-time analysis of spectral data. It supports classification, denoising, decomposition, and outlier detection of both single- and multi-component spectra. Instead of relying on large, computationally intensive models, it employs a novel supervised approach to non-negative matrix factorization (NMF) for dimensionality reduction. This ensures a fast, efficient, and adaptable analysis while reducing computational costs. \textsc{gamma\_flow} achieves classification accuracies above 90\% and enables reliable automated spectral interpretation. Originally developed for gamma-ray spectra, it is applicable to any type of one-dimensional spectral data. As an open and flexible alternative to proprietary software, it supports various applications in research and industry.
\end{abstract}

\begin{keyword}
Python \sep Gamma spectroscopy \sep Non-negative Matrix Factorization \sep Classification \sep Denoising \sep Spectral Deconvolution

\PACS 07.05.Kf % Data processing: signal processing and data analysis in physics instrumentation
\sep 29.30.Kv % X- and gamma-ray spectroscopy (in nuclear instrumentation)
\sep 02.50.Sk % Multivariate analysis (Statistische Verfahren, Machine Learning) 

\MSC[2020] 15A23 % Factorization of matrices
\sep 62H25 % Factor analysis and principal components; correspondence analysis 
\sep 65D10 % Smoothing, curve fitting, Denoising

\end{keyword}

\end{frontmatter}

%\linenumbers

\section*{Metadata}


\begin{table}[!ht]
\begin{tabular}{|l|p{6.5cm}|p{6.5cm}|}
\hline
\textbf{Nr.} & \textbf{Code metadata description} & \textbf{Metadata} \\
\hline
TO DO C1 & Current code version & 0.9.0 \\
\hline
C2 & Permanent link to code/repository used for this code version & \url{https://gitlab.opencode.de/uba-ki-lab/gamma_flow} \\
\hline
C3  & Permanent link to Reproducible Capsule & - \\
\hline
C4 & Legal Code License & BSD 3-Clause "New" or "Revised" License \\
\hline
C5 & Code versioning system used & git\\
\hline
C6 & Software code languages, tools, and services used & Python \\
\hline
C7 & Compilation requirements, operating environments \& dependencies & Python >= 3.12, matplotlib, numpy, pandas, scikit\_learn, scipy, seaborn, openpyxl \\
\hline
C8 & If available Link to developer documentation/manual & \url{https://gitlab.opencode.de/uba-ki-lab/gamma_flow/-/blob/main/README.md?ref_type=heads} \\
\hline
C9 & Support email for questions & raedle.htwk - AT - web.de\\
\hline
\end{tabular}
\caption{Code metadata (mandatory)}
\label{codeMetadata} 
\end{table}


\begin{table}[!ht]
\begin{tabular}{|l|p{6.5cm}|p{6.5cm}|}
\hline
\textbf{Nr.} & \textbf{(Executable) software metadata description} & \textbf{Please fill in this column} \\
\hline
S1 & Current software version & 0.9.0 \\
\hline
S2 & Permanent link to executables of this version  & \url{https://gitlab.opencode.de/uba-ki-lab/gamma_flow} \\
\hline
S3  & Permanent link to Reproducible Capsule & - \\
\hline
S4 & Legal Software License & BSD 3-Clause "New" or "Revised" License \\
\hline
S5 & Computing platforms/Operating Systems & Linux, Microsoft Windows\\
\hline
S6 & Installation requirements \& dependencies & Python >= 3.12, matplotlib, numpy, pandas, scikit\_learn, scipy, seaborn, openpyxl \\
\hline
S7 & If available, link to user manual - if formally published include a reference to the publication in the reference list &  \url{https://gitlab.opencode.de/uba-ki-lab/gamma_flow/-/tree/main/documentation?ref_type=heads} \\
\hline
S8 & Support email for questions & raedle.htwk - AT - web.de\\
\hline
\end{tabular}
\caption{Software metadata (optional)}
\label{executabelMetadata} 
\end{table}


\section{Motivation and significance}

Most radioactive sources can be identified by measuring their emitted radiation (X-rays and gamma rays), and visualizing them as a spectrum. In nuclear security applications, the resulting gamma spectra have to be analyzed in real-time as immediate reaction and decision making may be required. 
However, the manual recognition of isotopes present in a spectrum constitutes a 
strenous, error-prone task that depends on expert knowledge. Hence, this raises 
the need for algorithms assisting in the initial categorization and recognizability 
of measured gamma spectra. 
The delineated use case brings along several requirements:  
\begin{itemize}
\item As mobile, room temperature detectors are often deployed in nuclear security applications, the produced spectra typically exhibit a rather low energy resolution. In addition, a high temporal resolution is required (usually around one spectrum per second), leading to a low acquisition time and a low signal-to-noise ratio. Hence, the model must be robust and be able to handle noisy data.  
\item For some radioactive sources, acquisition of training spectra may be challenging. Instead, spectra of those isotopes are simulated using Monte Carlo N-Particle (MCNP) code \cite{Kulesza2022}. In this process, energy deposition in a detector material is simulated, yielding spectra that can be used for model training. However, simulated spectra and measured spectra from real-world sources may differ, which may be a constraint for model performance. On this account, preliminary data exploration is crucial to assess the similarity of spectral data from different detectors and to evaluate potential data limitations.  
\item Lastly, not only the correct classification of single-label test spectra (stemming from one isotope) is necessary, but also the decomposition of linear combinations of various isotopes (multi-label spectra). Hence, classification approaches like k-nearest-neighbours that solely depend on the similarity between training and test spectra are not applicable.  
\end{itemize} 
This paper presents \textsc{gamma\_flow}, a Python package designed for the real-time analysis of one-dimensional spectra. It was developed in response to the practical challenges described above and supports the following tasks:
\begin{itemize}
\item classification of test spectra to identify their constituents,  
\item denoising to enhence visibility and reduce measurement noise,
\item outlier detection to evaluate the model's applicability to unknown spectra.   
\end{itemize}

Originally developed for gamma spectroscopy, \textsc{gamma\_flow} is applicable to various domains including material science, chemistry, and environmental monitoring. It facilitates automated analysis in settings where fast interpretation of spectral data is essential. By integrating supervised dimensionality reduction with classical signal processing techniques, it extends prior work such as that of Bilton et al. \cite{Bilton2019}, contributing to reproducible and interpretable spectral analysis pipelines.



\section{Software description}
\label{sec:software_description}

\textsc{gamma\_flow} is based on a dimensionality reduction model that constitutes a novel, supervised approach to non-negative matrix factorization (NMF). More explicitly, the spectral data matrix is decomposed into the product of two low-rank matrices denoted as the scores (spectral data in latent space) and the loadings (transformation matrix or latent components). The loadings matrix is predefined and consists of the mean spectra of the training isotopes. Hence, by design, the scores axes correspond to the share of an isotope in a spectrum, resulting in an interpretable latent space. As a result, the classification of a test spectrum can be read directly from its (normalized) scores. In particular, shares of individual isotopes in a multi-label spectrum can be identified. This leads to an explainable quantitative prediction of the spectral constituents. 

For spectral denoising, the scores are transformed back into spectral space by applying the inverse model. This inverse transformation rids the test spectrum of noise and results in a smooth, easily recognizable denoised spectrum. 

If a test spectrum of an isotope is unknown to the model (i.e. this isotope was not included in model training), it can still be projected into latent space. However, when the latent space information (scores) are decompressed, the resulting denoised spectrum does not resemble the original spectrum any more. Some original features may not be captured while new peaks may have been fabricated. This can be quantified by calculating the cosine similarity between the original and the denoised spectrum, which can serve as an indicator of a test spectrum 
to be an outlier.

\subsection{Software architecture}
\textsc{gamma\_flow} consists of three jupyter notebooks that are executed consecutively, as depicted in Figure \ref{fig:software_architecture}. Each imports functions from a designated Python file, e.g. all functions called in \texttt{02\_model.ipynb} are found in \texttt{tools\_model.py}. In addition, the Python files \texttt{util.py}, \texttt{globals.py} and \texttt{plotting.py} provide elementary for all three notebooks. 

\begin{figure}[ht]
\includegraphics[width=\textwidth]{software_architecture_gamma_flow.pdf}
\caption{Software architecture of \textsc{gamma\_flow}: The jupyter notebooks \texttt{01\_preprocessing.ipynb}, \texttt{02\_model.ipynb} and \texttt{03\_outlier.ipynb} are executed consecutively, using functions from different Python files. }
\label{fig:software_architecture}
\end{figure}

\subsection{Software functionalities}

In this section, the functionality of the software is outlined, with an emphasis on the mathematical structure of the model. To this end, the procedures realised in the three jupyter notebooks \texttt{01\_preprocessing.ipynb}, \texttt{02\_model.ipynb} and \texttt{03\_outlier.ipynb} are delineated. In the software repository, a sample dataset of gamma spectra with examplary results is provided to give users a first insight into the software. 

\subsubsection{Preprocessing and data exploration}  
The notebook \texttt{01\_preprocessing.ipynb} synchronizes spectral data and provides a framework of visualizations for data exploration. All functions called in this notebook are found in \texttt{tools\_preprocessing.py}. 

During \textbf{preprocessing}, the following steps are performed:   
\begin{itemize}
\item Spectral data files are converted from .xlsm/.spe data to .npy format and saved.  
\item Spectra of different energy calibrations are rebinned to a standard energy calibration.  
\item Spectral data are aggregated by label classes and detectors. Thus, it is possible to 
  collect data from different files and formats.  
\item Optional: The spectra per isotope are limited to a maximum number (for class balance).  
\item The preprocessed spectra are saved as .npy files.  
\end{itemize}


\textbf{Data exploration} involves the following visualizations: 
\begin{itemize}
\item For each label class (e.g. for each isotope), the mean spectra are calculated detector-wise and compared 
  quantitatively by the cosine similarity.  
\item For each label class, example spectra are chosen randomly and plotted to provide an overview
  over the data.  
\item The cosine similarity is calculated and visualized as a matrix for all label classes and detectors. 
\end{itemize}
This helps to assess whether the model can handle spectra from different detectors.   


\subsubsection{Model training and testing}
\label{sec:model_training_testing}
The notebook \texttt{02\_model.ipynb} trains and tests a dimensionality reduction model that allows for denoising, classification and outlier detection of test spectra. All functions called in this notebook are found in \texttt{tools\_model.py}. \\

\textbf{The model} presented in this paper comprises a matrix decomposition of spectral data for dimensionality reduction. More precisely, the original spectra matrix $X$ is reconstructed by two low-rank matrices $S$ and $L$:  
$$ X \approx S  L^{T} $$  
with $S$: scores matrix (spectra in latent space) \\  
\hspace*{0.8cm} $L$: loadings matrix (transformation matrix or latent components). \\ 

\begin{figure}
\includegraphics[width=\textwidth]{matrix_decomposition.png}
\caption{Decomposition of spectral data into scores and loadings, illustrated for five different isotopes. The loadings matrix contains the latent components, corresponding to the mean spectrum of each isotope. The scores matrix provides the representation of each spectrum in the five-dimensional latent space. When normalized, the scores indicate the predicted contribution of each isotope to the measured spectrum.}
\label{fig:matrix_decomposition}
\end{figure}

As illustrated in Figure \ref{fig:matrix_decomposition}, original spectral data can be compressed into $k_\mathrm{isotopes}$ dimensions. To ensure a conclusive assignment of the latent space axes to the isotopes (i.e. one axis stands for of one isotope), the loadings matrix is predefined as the mean spectra of the $k_\mathrm{isotopes}$ isotopes. It represents the latent components and serves as transformation matrix between spectral space and latent space.

In mathematical terms, this model represents a supervised approach to Non-negative Matrix Factorization \cite{Shreeves2020, Bilton2019}. While dimensionality reduction is conventionally an unsupervised task as it only considers data structure \cite{Olaya2022}, our approach integrates labels in model training. This leads to an interpretable latent space and obviates the need for an additional classification step. In constrast to other supervised NMF approaches that incorporate classification loss in model training \cite{Leuschner2019, Lee2010, Bisot2016}, our model focuses on a comprehensible construction of the latent space. \\

During model training, mean spectra for all isotopes are calculated. The scores are then derived by a non-negative least squares fit of the original spectra to the loadings matrix. This enables the \textbf{spectral decomposition} and \textbf{classification} of the spectra, as the components of the normalized scores vectors directly reveal the contributions of the individual isotopes. \textbf{Denoised spectra}, on the other hand, are computed by transforming the non-normalized scores back into spectral space (i.e. by multiplication with the loadings matrix). \\

To assess \textbf{model performance}, the model is trained using spectral data from the specified detectors \texttt{dets\_tr} and isotopes \texttt{isotopes\_tr} and inferenced (i.e. scores are calculated) on three different test datasets:
\begin{enumerate}
\item validation data/holdout data from same detector as used in training (each spectrum including 
only one isotope or pure background)
\item test data from different detector (each spectrum including one isotope and background)
\item multi-label test data from different detector (each spectrum including multiple isotopes and background)
\end{enumerate}


For all test datasets, spectra are classified and denoised. The results are visualized as 
\begin{itemize}
\item confusion matrix  
\item misclassified spectra  
\item denoised example spectrum  
\item misclassification statistics  
\item scores as scatter matrix  
\item mean scores as bar plot
\end{itemize}
  
This helps to assess model performance with respect to classification and denoising. 

\subsubsection{Outlier analysis}
\label{sec:outlier_analysis}
The notebook \texttt{03\_outlier.ipynb} provides an exploratory approach to outliers detection, i.e. to identify spectra from isotopes that were not used in model training. All functions called in this notebook are found in \texttt{tools\_outlier.py}. 

To simulate outlier spectra, a mock dataset is generated by training a model after removing one specific isotope. The trained model is then inferenced on spectra of this unknown isotope to investigate its behaviour with outliers. 
First, the resulting latent space distribution and further meta data are analyzed to distinguish known from unknown spectra. Using a decision tree, the most informative feature is identified. 
Next, a decision boundary is derived for this feature, by  \\
a) using the condition of the first split in the decision tree \\
b) fitting a logistic regression (sigmoid function) to the data \\ 
c) setting a manual threshold by considering accuracy, precision and recall of outlier identification. \\
The derived decision boundary can then be implemented in the measurement pipeline by the user. \\


Apart from the jupyter notebooks and python files described above, the project includes the following python files:  
\begin{itemize}
\item \texttt{globals.py}: global variables  
\item \texttt{plotting.py}: all visualizations and plotting routines    
\item \texttt{util.py}: basic functions that are used by all notebooks  
\end{itemize}


\section{Illustrative example}

The major functions of \texttt{gamma\_flow} include classification, denoising, decomposition, and outlier detection of spectra. In this section, these capabilities are demonstrated using an illustrative example. 

A model is trained based on spectra of the isotopes Americium-241 (\textsuperscript{241}Am), Cobalt-60 (\textsuperscript{60}Co), Caesium-137 (\textsuperscript{137}Cs), Europium-152 (\textsuperscript{152}Eu), and pure background. The spectra are acquired using detector \texttt{det\_tr}, and the isotope spectra are free of background radiation.

The model is then inferenced on various test datasets to assess its performance in different scenarios (for more detail, see Section~\ref{sec:model_training_testing}). The following example focuses on test dataset 2, in which test spectra were recorded using a different detector. Each test spectrum contains either a single isotope combined with background or pure background only; no background subtraction was applied.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{Confusion_matrix_.pdf}
\caption{Confusion matrix of single-label classification, with an accuracy of 94.8\%. While the model was trained on spectra from detector \texttt{det\_tr}, spectra from a different detector were used as test data. Misclassifications only occur between an isotope and background, not between different isotopes.}
\label{fig:confusion_matrix}
\end{figure}

The \textbf{classification} results for this test dataset can be seen in Figure \ref{fig:confusion_matrix}, where the predicted labels are plotted against the ground truth as a confusion matrix. Correct classifications are highlighted with green borders while misclassifications are framed in red. Despite the difference between training and test spectra (different detector and presence of background in test data), an overall accuracy of 94.8\% is achieved. Notably, all misclassifications involve confusion between an isotope and pure background — never between two isotopes. Such cases typically occur when the isotope signal is near the detection threshold and the model's prediction deviates from the manually assigned label. Please refer to the software documentation in the code repository for further visualizations on model training and classification results, such as the loadings, the scores (visualized as scatter matrix), the mean predicted scores by isotope, misclassified example spectra and misclassification statistics. \\

As described in Section \ref{sec:software_description}, test spectra are \textbf{denoised} by transforming the scores back into spectral space by multiplication with the loadings matrix. The resulting spectra are significantly smoother and easier to interpret. A denoised example spectrum of \textsuperscript{137}Cs and background is depicted in Figure \ref{fig:denoised_spectrum}. As can be seen in the annotations, the predictions are correct, with an additional information on the contribution of the components: The model predicts 16\% share of \textsuperscript{137}Cs and 83\% background. The reconstruction of the original spectrum by the denoised spectrum is quantified by their cosine similarity of 0.99 and the explained variance ration of 98.14\%, which both indicate a successfull denoising process. \\

\begin{figure}
\includegraphics[width=\textwidth]{Denoised_Cs137.png}
\caption{Original and denoised spectrum of \textsuperscript{137}Cs and background. The denoised spectrum is smoother, leading to an easy and fast interpretability.}
\label{fig:denoised_spectrum}
\end{figure}

The options for \textbf{outlier detection} are analyzed as described in Section \ref{sec:outlier_analysis}. After the most informative feature is determined (in our case the cosine similarity between original and denoised spectrum) a decision boundary is derived. This can be done manually by considering accuracy, precision and recall, as visualized in Figure \ref{fig:outlier}. Those quantities yield different information on the separation of known and unknown spectra:
\begin{itemize}
\item \textbf{Accuracy} quantifies the correct classifications as known and unknown spectra: $\frac{\mathrm{True\;Positives + True\;Negatives}}{\mathrm{True\;Positives + False\;Positives + True\;Negatives + False\;Negatives}}$
\item \textbf{Precision} quantifies how many of the predicted outliers are actually unknown spectra: $\frac{\mathrm{True\;Positives}}{\mathrm{True\;Positives + False\;Positives}}$
\item \textbf{Recall} quantifies how many of the unknown spectra are found: \\$\frac{\mathrm{True\;Positives}}{\mathrm{True\;Positives + False\;Negatives}}$
\end{itemize}
In this example, a threshold between 0.5 and 0.9 would be an adequate choice. 

\begin{figure}
\includegraphics[width=\textwidth]{outlier_accuracy_precision_recall.png}
\caption{For outlier detection, the decision boundary can be derived based on accuracy, precision and recall of the outliers dataset. }
\label{fig:outlier}
\end{figure}


\section{Impact}
In many research fields, spectral measurements help to assess material properties. 
In this context, an area of interest for many researchers is the classification (automated labelling) of the measured spectra. Proprietary spectral analysis software, however, are often limited in their functionality and adaptability \cite{Lam2011, Nasereddin2023}. In addition, the underlying mechanisms are usually not revealed and may act as a black-box system to the user \cite{ElAmri2022}. On top of that, a spectral comparison is typically only possible for spectra of pure substances \cite{Cowger2021}. However, there may be a need to decompound multi-label spectra (linear combinations of different substances) and identify their constituents. 

\textsc{gamma\_flow} is a Python package that can assist researchers in the classification, denoising and outlier detection of spectra. It includes data preprocessing, data exploration, model training and testing as well as an exploratory section on outlier detection. Making use of matrix decomposition methods, the designed model is lean and performant. Training and inference do not require special hardware or extensive computational power. This allows real-time application on ordinary laboratory computers and easy implementation into the measurement routine. 

The provided example dataset contains gamma spectra of several measured and simulated isotopes as well as pure background spectra. While this package was developed in need of an analysis tool for gamma spectra, it is suitable for any one-dimensional spectra. Examplary applications encompass  
\begin{itemize}
\item \textbf{Infrared spectroscopy} for the assessment of the polymer composition of 
microplastics in water \cite{Ferreiro2023, Whiting2022}  
\item \textbf{mass spectrometry} for protein identification in snake venom 
\cite{Zelanis2019, Yasemin2021}  
\item \textbf{Raman spectroscopy} for analysis of complex pharmaceutical mixtures and detection
of dilution products like lactose \cite{Fu2021}  
\item \textbf{UV-Vis spectroscopy} for detection of pesticides in surface waters \cite{Guo2020, Qi2024}
\item \textbf{stellar spectroscopy} to infer the chemical composition of stars \cite{Gray2021}  
\end{itemize}


\section{Conclusions}
In this paper, we introduced \textsc{gamma\_flow}, an open-source, Python-based framework for the analysis of one-dimensional spectra. The approach combines established data science techniques in a resource-efficient way, enabling real-time analysis at low computational cost. Based on a supervised variant of non-negative matrix factorization, it constructs a fast and interpretable model for classification, decomposition, denoising, and outlier detection of spectral data. The method is applicable to both pure (single-label) and mixed (multi-label) spectra. 

For a user-friendly implementation, the software is organized into three jupyter notebooks executed sequentially. Each notebook combines explanatory text with code, guiding users step-by-step through data preprocessing and exploration, model training and evaluation, and outlier detection. This enables users not only to apply the model to spectral data but also develop a deep understanding of the underlying processes - without requiring advanced mathematical or programming expertise.  

\textsc{gamma\_flow} bridges the gap between complex, often proprietary spectral analysis tools and the limitations of manual interpretation in laboratory workflows. By offering an open, transparent, and extensible framework, it empowers researchers to move beyond traditional black-box approaches. With its modular architecture and general applicability, it opens new avenues for innovation across disciplines — from nuclear safety and materials science to environmental monitoring and beyond. As such, \textsc{gamma\_flow} has the potential to accelerate scientific discovery wherever spectral data plays a role.

\section*{Acknowledgements}
We gratefully acknowledge the support provided by the Federal Ministry for the Environment, Nature Conservation and Nuclear Safety (BMUV), whose funding has been instrumental in enabling us to achieve our research objectives and explore new directions. 
We also extend our appreciation to Martin Bussick in his function as the AI coordinator. 
Additionally, we thank the entire AI-Lab team for their support and inspiration, with special recognition to Ruth Brodte for guidance on legal and licensing matters.

\bibliographystyle{elsarticle-num} 
\bibliography{gamma_flow_SoftwareX.bib}



\end{document}
\endinput
%%
%% End of file `SoftwareX_article_template.tex'.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
